{"cells": [{"metadata": {}, "cell_type": "code", "source": "#!pip install beautifulsoup4\n#!pip install lxml\nimport requests # library to handle requests\nimport pandas as pd # library for data analsysis\nimport numpy as np # library to handle data in a vectorized manner\nimport random # library for random number generation\nimport time\nimport pickle\n#!pip install selenium\nfrom selenium import webdriver\nimport glob\nimport os\nimport csv\n\n#!conda install -c conda-forge geopy --yes \nfrom geopy.geocoders import Nominatim # module to convert an address into latitude and longitude values\n\n# libraries for displaying images\nfrom IPython.display import Image \nfrom IPython.core.display import HTML \n\n\nfrom IPython.display import display_html\nimport pandas as pd\nimport numpy as np\n    \n# tranforming json file into a pandas dataframe library\nfrom pandas.io.json import json_normalize\n\n#!conda install -c conda-forge folium=0.5.0 --yes\nimport folium # plotting library\nfrom bs4 import BeautifulSoup\nfrom sklearn.cluster import KMeans\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\nprint('Folium installed')\nprint('Libraries imported.')", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "Folium installed\nLibraries imported.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# create useful function\ndef change_values(df):\n    \"\"\"\n    change dataframe values from \"-\" to 0\n    \"\"\"\n    mapping = {'-' : 0}\n    replace_dict = {}\n    for columns in df.columns:\n        replace_dict[columns] = mapping\n        \n    return df.replace(replace_dict)", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def crawling_league_teams(team_id, api_delay_term=5):\n    \"\"\"\n    get league name and team name\n    \n    parameter ---------------------------------------------------------------\n    team_id : (int or str) team_id\n    api_delay_term = (optional) 5\n    \n    return ------------------------------------------------------------------\n    pandas dataframe columns=team_id, team_name\n    \"\"\"\n    \n    # connect webdriver\n    url = \"https://www.whoscored.com/Teams/\" + str(team_id)\n    driver =  webdriver.PhantomJS()\n    driver.get(url)\n    \n    # wait get league team datas\n    time.sleep(api_delay_term) \n    \n    # make pandas dataframe\n    team_df = pd.DataFrame(columns=[\"team_id\",\"team_name\"])\n    \n    # get team datas\n    teams = driver.find_elements_by_css_selector(\"#teams option\")\n    for team in teams:\n        team_name = team.text\n        team_id = team.get_attribute(\"value\").split(\"/\")[2]\n        team_df.loc[len(team_df)] = {\"team_id\" : team_id, \"team_name\" : team_name }\n        \n    # close webdriver\n    driver.close()\n    \n    return replace_pd(team_df)", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def crawling_player_summary(team_id, api_delay_term=5):\n    \"\"\"\n    crawling player summary data \n        \n    parameter -------------------------------------------------------------------\n    team_id : (int or str) team_id\n    api_delay_term = (optional) 5\n    \n    return ----------------------------------------------------------------------\n    pandas dataframe\n    columns = player_nuber, flag, name, age, position, tall, weight, full_time, half_time\n    , mins, goals, asists, yel, red, spg, ps, motm, aw, rating\n    \n    \"\"\"    \n    \n    # connect webdriver\n    url = \"https://www.whoscored.com/Teams/\" + str(team_id)\n    driver =  webdriver.PhantomJS()\n    driver.get(url)\n\n    # wait for getting data\n    time.sleep(api_delay_term)\n    \n    # make pandas dataframe\n    player_summary_df = pd.DataFrame(columns=[\n            \"player_number\", \"flag\", \"name\", \"age\", \"position\"\n            , \"tall\", \"weight\", \"full_time\", \"half_time\", \"mins\"\n            , \"goals\", \"asists\", \"yel\", \"red\", \"spg\", \"ps\", \"motm\"\n            , \"aw\", \"rating\",\n        ])\n    \n    # get player summay datas\n    elements = driver.find_elements_by_css_selector(\"#player-table-statistics-body tr\")\n    for element in elements:\n        \n        # split full time games and half time games\n        games = element.find_elements_by_css_selector(\"td\")[5].text\n        games = games.split(\"(\")\n        full_time, half_time = games[0], 0\n        if len(games) > 1 :\n            half_time = games[1].replace(\")\",\"\")\n        else :\n            half_time = 0\n        \n        # player dictionary data\n        player_dict = { \n            \"player_number\": element.find_elements_by_css_selector(\"td\")[2].find_elements_by_css_selector(\"a\")[0].get_attribute(\"href\").split(\"/\")[4], \n            \"flag\": element.find_elements_by_css_selector(\"td\")[1].find_elements_by_css_selector(\"span\")[0].get_attribute(\"class\").split(\"-\")[2],\n            \"name\": element.find_elements_by_css_selector(\"td\")[2].find_elements_by_css_selector(\"a\")[0].text, \n            \"age\": element.find_elements_by_css_selector(\"td\")[2].find_elements_by_css_selector(\"span\")[0].text, \n            \"position\": element.find_elements_by_css_selector(\"td\")[2].find_elements_by_css_selector(\"span\")[1].text[1:], \n            \"tall\": element.find_elements_by_css_selector(\"td\")[3].text,\n            \"weight\": element.find_elements_by_css_selector(\"td\")[4].text, \n            \"full_time\": full_time,\n            \"half_time\": half_time,\n            \"mins\": element.find_elements_by_css_selector(\"td\")[6].text,\n            \"goals\": element.find_elements_by_css_selector(\"td\")[7].text,\n            \"asists\": element.find_elements_by_css_selector(\"td\")[8].text,\n            \"yel\": element.find_elements_by_css_selector(\"td\")[9].text,\n            \"red\": element.find_elements_by_css_selector(\"td\")[10].text,\n            \"spg\": element.find_elements_by_css_selector(\"td\")[11].text,\n            \"ps\": element.find_elements_by_css_selector(\"td\")[12].text,\n            \"aw\": element.find_elements_by_css_selector(\"td\")[13].text,\n            \"motm\": element.find_elements_by_css_selector(\"td\")[14].text,\n            \"rating\": element.find_elements_by_css_selector(\"td\")[15].text,\n        }\n        \n        player_summary_df.loc[len(player_summary_df)] = player_dict\n    \n    # close webdriver\n    driver.close()\n    \n    return replace_pd(player_summary_df)", "execution_count": 10, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\ndef crawling_player_defensive(team_id, api_delay_term=5):\n    \"\"\"\n    crawling player defensive data \n        \n    parameter -------------------------------------------------------------------\n    team_id : (int or str) team_id\n    api_delay_term = (optional) 5\n    \n    return ----------------------------------------------------------------------\n    pandas dataframe\n    columns = player_number, tackles, inter, fouls, offsides, clear, drb, blocks, owng\n    \n    \"\"\"  \n\n    # connect webdriver\n    url = \"https://www.whoscored.com/Teams/\" + str(team_id)\n    driver =  webdriver.PhantomJS()\n    driver.get(url)\n    \n    # wait for getting data\n    time.sleep(api_delay_term)\n    \n    # click event for getting defensive data\n    driver.find_elements_by_css_selector(\"#team-squad-stats-options .in-squad-detailed-view\")[0].find_element_by_css_selector(\"a\").click()\n    \n    # wait for getting data\n    time.sleep(api_delay_term)\n    \n    # make pandas dataframe\n    player_defensive_df = pd.DataFrame(columns=[\n            \"player_number\", \"tackles\", \"inter\", \"fouls\", \"offsides\", \"clear\", \"drb\", \"blocks\", \"owng\"\n        ])\n    \n    # get player defensive datas\n    elements = driver.find_elements_by_css_selector(\"#team-squad-stats-defensive #player-table-statistics-body tr\")\n    for element in elements:\n       \n        player_dict = {\n            \"player_number\": element.find_elements_by_css_selector(\"td\")[2].find_elements_by_css_selector(\"a\")[0].get_attribute(\"href\").split(\"/\")[4], \n            \"tackles\": element.find_elements_by_css_selector(\"td\")[7].text, \n            \"inter\": element.find_elements_by_css_selector(\"td\")[8].text, \n            \"fouls\": element.find_elements_by_css_selector(\"td\")[9].text,\n            \"offsides\": element.find_elements_by_css_selector(\"td\")[10].text,\n            \"clear\": element.find_elements_by_css_selector(\"td\")[11].text,\n            \"drb\": element.find_elements_by_css_selector(\"td\")[12].text,\n            \"blocks\": element.find_elements_by_css_selector(\"td\")[13].text,\n            \"owng\": element.find_elements_by_css_selector(\"td\")[14].text,\n        }\n        \n        player_defensive_df.loc[len(player_defensive_df)] = player_dict\n    \n    # close webdriver\n    driver.close()\n    \n    return replace_pd(player_defensive_df)", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def crawling_player_offensive(team_id, api_delay_term=5):\n    \n    \"\"\"\n    crawling player offensive data \n        \n    parameter -------------------------------------------------------------------\n    team_id : (int or str) team_id\n    api_delay_term = (optional) 5\n    \n    return ----------------------------------------------------------------------\n    pandas dataframe\n    columns = player_number, keyp, fouled, off, disp, unstch\n    \n    \"\"\"  \n\n    # connect webdriver\n    url = \"https://www.whoscored.com/Teams/\" + str(team_id)\n    driver =  webdriver.PhantomJS()\n    driver.get(url)\n    \n    # wait for getting data\n    time.sleep(api_delay_term)\n    \n    # click event for getting data\n    driver.find_elements_by_css_selector(\"#team-squad-stats-options .in-squad-detailed-view\")[1].find_element_by_css_selector(\"a\").click()\n    \n    # wait for getting data\n    time.sleep(api_delay_term)\n    \n    # make pandas dataframe\n    player_offensive_df = pd.DataFrame(columns=[\"player_number\", \"keyp\", \"fouled\", \"off\", \"disp\", \"unstch\"])\n    \n    # get player offensive datas\n    elements = driver.find_elements_by_css_selector(\"#statistics-table-offensive #player-table-statistics-body tr\")\n    for element in elements:\n    \n        player_dict = {\n            \"player_number\": element.find_elements_by_css_selector(\"td\")[2].find_elements_by_css_selector(\"a\")[0].get_attribute(\"href\").split(\"/\")[4], \n            \"keyp\": element.find_elements_by_css_selector(\"td\")[10].text, \n            \"fouled\": element.find_elements_by_css_selector(\"td\")[12].text, \n            \"off\": element.find_elements_by_css_selector(\"td\")[13].text,\n            \"disp\": element.find_elements_by_css_selector(\"td\")[14].text,\n            \"unstch\": element.find_elements_by_css_selector(\"td\")[15].text,\n        }\n        \n        player_offensive_df.loc[len(player_offensive_df)] = player_dict\n        \n    # close webdriver\n    driver.close()\n    \n    return replace_pd(player_offensive_df)", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def crawling_player_passing(team_id, api_delay_term=5):\n    \n    \"\"\"\n    crawling player passing data \n        \n    parameter -------------------------------------------------------------------\n    team_id : (int or str) team_id\n    api_delay_term = (optional) 5\n    \n    return ----------------------------------------------------------------------\n    pandas dataframe belong player's ability\n    player_number, avgp, ps, crosses, longb, thrb\n    \n    \"\"\" \n    \n    # connect webdriver\n    url = \"https://www.whoscored.com/Teams/\" + str(team_id)\n    driver =  webdriver.PhantomJS()\n    driver.get(url)\n    \n    # wait for gettig data\n    time.sleep(api_delay_term)\n    \n    # click event for gettig data\n    driver.find_elements_by_css_selector(\"#team-squad-stats-options .in-squad-detailed-view\")[2].find_element_by_css_selector(\"a\").click()\n\n    # wait for gettig data\n    time.sleep(api_delay_term)\n    \n    # make pnadas dateframe\n    player_passing_df = pd.DataFrame(columns=[\n            \"player_number\", \"avgp\", \"ps\", \"crosses\", \"longb\", \"thrb\"\n        ])\n\n    # get data\n    elements = driver.find_elements_by_css_selector(\"#statistics-table-passing #player-table-statistics-body tr\")\n    for element in elements:\n       \n        player_dict = {\n            \"player_number\": element.find_elements_by_css_selector(\"td\")[2].find_elements_by_css_selector(\"a\")[0].get_attribute(\"href\").split(\"/\")[4], \n            \"avgp\": element.find_elements_by_css_selector(\"td\")[8].text, \n            \"ps\": element.find_elements_by_css_selector(\"td\")[9].text, \n            \"crosses\": element.find_elements_by_css_selector(\"td\")[10].text,\n            \"longb\": element.find_elements_by_css_selector(\"td\")[11].text,\n            \"thrb\": element.find_elements_by_css_selector(\"td\")[12].text,\n        }\n        \n        player_passing_df.loc[len(player_passing_df)] = player_dict\n    \n    # close webdriver\n    driver.close()\n    \n    return replace_pd(player_passing_df)", "execution_count": 13, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# save league and team name using leauge_teams function\ndef save_league_teams(league_name, team_id):    \n    league_teams = crawling_league_teams(team_id)\n    league_teams.to_csv(\"./league/\" + league_name + \".csv\", index=False)\n    return league_teams", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def make_player_info(team_id, team_name):\n    \"\"\"\n    cralwing player data and merge player data(summary, defensive, offensive, passing)\n    \n    parameter ----------------------------------------------\n    team_id : int or str, you want to get team_id of players\n    team_name : str, team_name\n    \n    return -------------------------------------------------\n    merged dataframe\n    \n    \"\"\"\n    \n    # excute player datas crawling functions \n    player_summary_df = crawling_player_summary(team_id)\n    player_defensive_df = crawling_player_defensive(team_id)\n    player_offensive_df = crawling_player_offensive(team_id)\n    player_passing_df = crawling_player_passing(team_id)\n    \n    # merge player datas\n    sd = player_summary_df.merge(player_defensive_df, on=\"player_number\")\n    sdo = sd.merge(player_offensive_df, on=\"player_number\")\n    merged_data = sdo.merge(player_passing_df, on=\"player_number\")\n    \n    # add team name\n    merged_data[\"team_name\"] = team_name\n    \n    return merged_data\n    \n\ndef save_players_in_the_league(league):\n    \"\"\"\n    make player data and save\n    \n    prameter  -----------------------------------------------------\n    league : (str) league name\n    \n    \"\"\"\n    \n    # get league team_id team_name dataframe\n    league_team_df = pd.read_csv(\"./league/\" + league + \".csv\")\n    \n    # get palyer dataframe function\n    def get_player_df(league, team_id, team_name):\n        players_df = make_player_info(team_id, team_name)\n        players_df.to_csv(\"./player/\" + league + \"/\" + team_name + \".csv\")\n        return players_df\n    \n    # for one of league teams\n    for idx, row in league_team_df.iterrows():\n        try_again_num = 0\n        print(\"Make Player {0} Start.\".format(row.team_name))\n\n        players_df = []\n        \n        # there is no player data, try crawling more 3 times\n        while len(players_df) == 0 and try_again_num < 3:\n            if try_again_num > 0:\n                print(\"Try Again! : player_data error\")\n            try_again_num += 1\n            players_df = get_player_df(league, row.team_id, row.team_name)\n            \n        print(\"The number of saved players : {0}\".format(len(players_df)))\n        print(\"Make Player {0} Done\".format(row.team_name))\n        print(\"-\" * 35)    \n        \n    print(league + \" Save Players Done!\")", "execution_count": 15, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# merge_csv files in the path to new_file\ndef concat_csv(path, new_file_name):\n    path = path\n    allfiles = glob.glob(os.path.join(path + \"*.csv\"))\n    frame = pd.DataFrame()\n    list_ = []\n    for file_ in allfiles:\n        df = pd.read_csv(file_, index_col=None, header=0)\n        list_.append(df)\n        \n    concat_df = pd.concat(list_, ignore_index=True)\n    concat_df.to_csv(new_file_name)\n    print(\"success\")", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "\n# Data\n"}, {"metadata": {}, "cell_type": "code", "source": "%matplotlib inline\n%config InlineBackend.figure_formats = {'png', 'retina'}\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport seaborn as sns\nimport MySQLdb\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_validation import cross_val_score", "execution_count": 17, "outputs": [{"output_type": "error", "ename": "ModuleNotFoundError", "evalue": "No module named 'MySQLdb'", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)", "\u001b[0;32m<ipython-input-17-83aa3cf422f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mMySQLdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'MySQLdb'"]}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}